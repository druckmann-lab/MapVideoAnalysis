import numpy as np
import os
from sklearn.model_selection import StratifiedKFold
from sklearn.linear_model import RidgeCV
from sklearn.metrics import r2_score

def get_file_paths(directory):
    """
    Get a list of full file paths in a given directory.

    Parameters:
    directory : str
        The path to the directory.

    Returns:
    list
        List of full file paths.
    """
    directory = os.path.abspath(directory)
    file_paths = []
    for filename in os.listdir(directory):
        full_path = os.path.join(directory, filename)
        if os.path.isfile(full_path):
            file_paths.append(full_path)
    return file_paths

def create_4fold_trial_type_mask(ephys_data):
    '''
    Creates a mask for trial stratification for cross-validation.
    
    The groups are:
    1: Hit right
    2: Miss right
    3: Hit left
    4: Miss left

    If group 2 or 4 has less than 2 members then 
    returns three groups:
    1: Hit right
    3. Hit left
    0. Miss
    
    '''
    trial_type = ephys_data['trial_type']
    correctness = ephys_data['correctness']
    mask = np.zeros_like(trial_type)
    mask[(trial_type == 0) * (correctness == 1)] = 1
    mask[(trial_type == 0) * (correctness == 0)] = 2
    mask[(trial_type == 1) * (correctness == 1)] = 3
    mask[(trial_type == 1) * (correctness == 0)] = 4

    if np.sum(np.array([np.sum(mask == i) for i in range(1,5)]) < 2) > 0:
        print('Warning: Some trial types have less than 2 trials. Pooling incorrect trials.')
        mask[(trial_type == 0)] = 1
        mask[(trial_type == 1)] = 3
        mask[(correctness == 0)] = 0
    return mask

def predict_single_split(model, X, y, trial_mask, split_inds, x_trial_inds):
    '''
    Predicts the firing rates for a single train-test split.

    Parameters
    ----------
    model : sklearn.linear_model
        The model to use for fitting, RidgeCV.
    X : np.ndarray
        The input data. Embedding or marker.
        Shaped [trials, features].
    y : np.ndarray
        The target data. Firing rates.
        Shaped [trials, neurons].
    trial_mask : np.ndarray
        The trial mask for stratification.
        Contains trail type and correctness.
    split_inds : dict
        The split indices.
    x_trial_inds : np.ndarray
        Corresponding trial indices for the input data.

    Returns
    -------
    r2_scores_per_fold : np.ndarray
        The R² scores for the test fold.
    y_test_per_fold : np.ndarray
        The target firing rate for the test fold.
    y_pred_per_fold : np.ndarray  
        The predicted firing rate for the test fold.
    test_masks : np.ndarray
        The trial masks for the fold.
    test_trial_inds : np.ndarray    
        The trial indices for the test fold.
    
    '''

    r2_scores_per_fold = []
    y_test_per_fold = []
    y_pred_per_fold = []
    test_masks = []
    test_trial_inds = []

    
    test_inds = split_inds['test']
    train_inds = split_inds['train']

    
    x_test_inds = np.array([np.where(x_trial_inds == i)[0][0] for i in test_inds])
    x_train_inds = np.array([np.where(x_trial_inds == i)[0][0] for i in train_inds])
    X_train, X_test = X[x_train_inds], X[x_test_inds]
    y_train, y_test = y[train_inds], y[test_inds]
    mask_train, mask_test = trial_mask[train_inds], trial_mask[test_inds]

    test_masks.append(mask_test)

    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    r2_scores = r2_score(y_test, y_pred, multioutput='raw_values')

    test_trial_inds.append(test_inds)
    r2_scores_per_fold.append(r2_scores)
    y_test_per_fold.append(y_test)
    y_pred_per_fold.append(y_pred)

    return np.array(r2_scores_per_fold).T, np.concatenate(y_test_per_fold, axis = 0), np.concatenate(y_pred_per_fold, axis = 0), np.concatenate(test_masks, axis = 0), np.concatenate(test_trial_inds, axis = 0)



def cross_validation_with_predefined_folds(model, X, y, trial_mask, fold_inds, x_trial_inds, cv=5):
    '''
    Cross validation for ridge regression that uses predefined folds.

    Parameters
    ----------
    model : sklearn.linear_model
        The model to use for fitting.

    X : np.ndarray  
        The input data. Embedding or marker.
    y : np.ndarray
        The target data. Firing rates.
    trial_mask : np.ndarray
        The trial mask for stratification.
    fold_inds : dict
        The fold indices.
    x_trial_inds : np.ndarray
        The trial indices for the input data.
    cv : int, optional
        The number of folds. The default is 5.

    Returns
    -------
    r2_scores_per_fold : np.ndarray
        The R² scores for each fold.
    y_test_per_fold : np.ndarray
        The target data for each fold.
    y_pred_per_fold : np.ndarray
        The predicted data for each fold.
    test_masks : np.ndarray
        The trial masks for each fold
    test_trial_inds : np.ndarray
        The trial indices for each test fold.
    '''

    r2_scores_per_fold = []
    y_test_per_fold = []
    y_pred_per_fold = []
    test_masks = []
    test_trial_inds = []

    for i_fold in range(cv):
        test_inds = fold_inds['test_%d'%i_fold]
        train_inds = fold_inds['train_%d'%i_fold]

        
        x_test_inds = np.array([np.where(x_trial_inds == i)[0][0] for i in test_inds])
        x_train_inds = np.array([np.where(x_trial_inds == i)[0][0] for i in train_inds])
        X_train, X_test = X[x_train_inds], X[x_test_inds]
        y_train, y_test = y[train_inds], y[test_inds]
        mask_train, mask_test = trial_mask[train_inds], trial_mask[test_inds]

        test_masks.append(mask_test)

        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)
        r2_scores = r2_score(y_test, y_pred, multioutput='raw_values')

        test_trial_inds.append(test_inds)
        r2_scores_per_fold.append(r2_scores)
        y_test_per_fold.append(y_test)
        y_pred_per_fold.append(y_pred)

    return np.array(r2_scores_per_fold).T, np.concatenate(y_test_per_fold, axis = 0), np.concatenate(y_pred_per_fold, axis = 0), np.concatenate(test_masks, axis = 0), np.concatenate(test_trial_inds, axis = 0)


def custom_cross_val_score(model, X, y, trial_mask, cv=5):
    '''
    Custom cross validation for ridge regression that returns the R² scores and fold predictions.

    Parameters
    ----------
    model : sklearn.linear_model
        The model to use for fitting.
    X : np.ndarray
        The input data.
    y : np.ndarray
        The target data.
    trial_mask : np.ndarray
        The trial mask for stratification.
    cv : int, optional
        The number of folds. The default is 5.
    
    Returns
    -------
    r2_scores_per_fold : np.ndarray
        The R² scores for each fold.
    y_test_per_fold : np.ndarray
        The target data for each fold.
    y_pred_per_fold : np.ndarray
        The predicted data for each fold.
    test_masks : np.ndarray
        The trial masks for each fold.
    '''

    kf = StratifiedKFold(n_splits=cv)
    r2_scores_per_fold = []
    y_test_per_fold = []
    y_pred_per_fold = []
    test_masks = []

    for train_index, test_index in kf.split(X, trial_mask):
        X_train, X_test = X[train_index], X[test_index]
        y_train, y_test = y[train_index], y[test_index]
        mask_train, mask_test = trial_mask[train_index], trial_mask[test_index]
        test_masks.append(mask_test)

        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)
        r2_scores = r2_score(y_test, y_pred, multioutput='raw_values')

        r2_scores_per_fold.append(r2_scores)
        y_test_per_fold.append(y_test)
        y_pred_per_fold.append(y_pred)

    return np.array(r2_scores_per_fold).T, np.concatenate(y_test_per_fold, axis = 0), np.concatenate(y_pred_per_fold, axis = 0), np.concatenate(test_masks, axis = 0)

find_closest = lambda x, x0: np.argmin(np.abs(x-x0))

def temporal_alignment_embed_and_ephys(ephys_tt,embed_tt, embed_vecs, fr, dt = 0.0034):
    '''Align the embeding vectors and the firing rates in time.
    
    This assumes that the dt is the same for both datasets.

    Parameters
    ----------
    ephys_tt : np.ndarray
        The time stamps for the ephys data.
    embed_tt : np.ndarray
        The time stamps for the embedding vectors.
    embed_vecs : np.ndarray [time, trial, embedding_dim]
        The embedding vectors.
    fr : np.ndarray [time, trial, neuron]
        The firing rates.
    dt : float, optional
        The time step. The default is 0.0034.

    Returns
    -------
    joint_tt : np.ndarray
        The time stamps for the joint data.
    joint_embed_vecs : np.ndarray
        The embedding vectors aligned to the ephys data.
    joint_fr : np.ndarray
        The firing rates aligned to the embedding vectors.
    '''
    if ephys_tt[0] < embed_tt[0]:
        embed_start_ind = 0
        ephys_start_ind = find_closest(ephys_tt, embed_tt[0] + dt/2)
    else: 
        embed_start_ind = find_closest(embed_tt, ephys_tt[0] - dt/2)
        ephys_start_ind = 0

    if ephys_tt[-1] > embed_tt[-1] + dt/2:
        embed_end_ind = len(embed_tt)
        ephys_end_ind = ephys_start_ind + embed_end_ind - embed_start_ind
    else:
        ephys_end_ind = len(ephys_tt)
        embed_end_ind = embed_start_ind + ephys_end_ind - ephys_start_ind

    joint_tt = ephys_tt[ephys_start_ind:ephys_end_ind]
    joint_embed_vecs = embed_vecs[embed_start_ind:embed_end_ind]
    joint_fr = fr[ephys_start_ind:ephys_end_ind]

    return joint_tt, joint_embed_vecs, joint_fr

def get_regular_trial_mask(ephys_data):
    '''
    Returns a mask for regular trials.
    
    No early lick, no auto water, no free water, no no response trials.
    '''
    return (ephys_data['early_lick_trials'] == 0) \
         * (ephys_data['auto_water_trials'] == 0)  \
         * (ephys_data['free_water_trials'] == 0)  \
         * (ephys_data['correctness'] != -1) \
         * (ephys_data['stimulation'][:,0] == 0)


def process_single_session_r2_dict(
        r2_dict, 
        sample_period = [-1.85,-1.2], 
        delay_period = [-1.2,0.], 
        response_period = [0, 1.5],
        timeshift = 0):
    '''
    Get average R2 scores for sample, delay and response periods.

    Calculates both the averages of the instantaneois R2 scores.
    And the R2 scores for all the trials and timepoints concatenated 
    within an epoch. This is the "old method". 

    Parameters
    ----------
    r2_dict : dict
        The dictionary containing the R2 scores.
    sample_period : list, optional
        The sample period. The default is [-1.85,-1.2].
    delay_period : list, optional
        The delay period. The default is [-1.2,0.].
    response_period : list, optional
        The response period. The default is [0, 1.5].
    timeshift : float, optional
        If there was timeshift between the video and firing rates.
        The default is 0.

    Returns
    -------
    sample_r2 : np.ndarray
        The average R2 scores for the sample period.
    delay_r2 : np.ndarray
        The average R2 scores for the delay period.
    response_r2 : np.ndarray   
        The average R2 scores for the response period.
    sample_r2_old : np.ndarray
        The average R2 scores for the sample period (old method).
    delay_r2_old : np.ndarray
        The average R2 scores for the delay period (old method).
    response_r2_old : np.ndarray
        The average R2 scores for the response period (old method).

    '''
    dt = 0.0034
    tt = r2_dict['tt']
    r2_scores = r2_dict['r2_scores']
    y_test = r2_dict['y_test']
    y_pred = r2_dict['y_pred']

    sample_mask = (tt >= sample_period[0]) * (tt < sample_period[1])
    sample_mask *= (tt >= (sample_period[0]-timeshift*dt)) * (tt < (sample_period[1]-timeshift*dt))
    delay_mask = (tt >= delay_period[0]) * (tt < delay_period[1])
    delay_mask *= (tt >= (delay_period[0]-timeshift*dt)) * (tt < (delay_period[1]-timeshift*dt))
    response_mask = (tt >= response_period[0]) * (tt < response_period[1])
    response_mask *= (tt >= (response_period[0]-timeshift*dt)) * (tt < (response_period[1]-timeshift*dt))

    sample_r2 = np.mean(r2_scores[sample_mask,:], axis = (0,2))
    delay_r2 = np.mean(r2_scores[delay_mask,:], axis = (0,2))
    response_r2 = np.mean(r2_scores[response_mask,:], axis = (0,2))

    sample_r2_old = r2_score(
        np.concatenate(y_test[sample_mask],axis = 0),
        np.concatenate(y_pred[sample_mask],axis = 0),
        multioutput='raw_values')
    delay_r2_old = r2_score(
        np.concatenate(y_test[delay_mask],axis = 0),
        np.concatenate(y_pred[delay_mask],axis = 0),
        multioutput='raw_values')
    response_r2_old = r2_score(
        np.concatenate(y_test[response_mask],axis = 0),
        np.concatenate(y_pred[response_mask],axis = 0),
        multioutput='raw_values')
    
    return sample_r2, delay_r2, response_r2, sample_r2_old, delay_r2_old, response_r2_old

def process_single_session_r2_dict_keepfolds(
        r2_dict, 
        sample_period = [-1.7,-1.35], 
        delay_period = [-1.05,-0.15], 
        response_period = [0.15, 1.2],):
    '''
    Get average R2 scores for sample, delay and response periods.

    Calculates both the averages of the instantaneois R2 scores.
    And the R2 scores for all the trials and timepoints concatenated 
    within an epoch. This is the "old method". 

    Parameters
    ----------
    r2_dict : dict
        The dictionary containing the R2 scores.
    sample_period : list, optional
        The sample period. The default is [-1.7,-1.35].
    delay_period : list, optional
        The delay period. The default is [-1.05,-0.15].
    response_period : list, optional
        The response period. The default is [0.15, 1.2].

    Returns
    -------
    sample_r2 : np.ndarray
        The average R2 scores for the sample period for each fold.
    delay_r2 : np.ndarray
        The average R2 scores for the delay period for each fold.
    response_r2 : np.ndarray   
        The average R2 scores for the response period for each fold.

    '''

    tt = r2_dict['tt']
    r2_scores = r2_dict['r2_scores']

    sample_mask = (tt >= sample_period[0]) * (tt < sample_period[1])
    delay_mask = (tt >= delay_period[0]) * (tt < delay_period[1])
    response_mask = (tt >= response_period[0]) * (tt < response_period[1])

    sample_r2 = np.mean(r2_scores[sample_mask,:], axis = (0))
    delay_r2 = np.mean(r2_scores[delay_mask,:], axis = (0))
    response_r2 = np.mean(r2_scores[response_mask,:], axis = (0))
    
    return sample_r2, delay_r2, response_r2
    

def get_epoch_average_fr(
        fr,
        tt,
        sample_period = [-1.85,-1.2], 
        delay_period = [-1.2,0.], 
        response_period = [0, 1.5]):
    '''
    Get the average firing rates for the sample, delay and response periods.

    Parameters
    ----------
    fr : np.ndarray
        The firing rates [time,trial,neuron].
    tt : np.ndarray
        The time stamps.

    Returns
    -------
    sample_fr : np.ndarray
        The average firing rates for the sample period.
    delay_fr : np.ndarray
        The average firing rates for the delay period.
    response_fr : np.ndarray
        The average firing rates for the response period.
    '''
    
    sample_mask = (tt >= sample_period[0]) * (tt < sample_period[1])
    delay_mask = (tt >= delay_period[0]) * (tt < delay_period[1])
    response_mask = (tt >= response_period[0]) * (tt < response_period[1])

    sample_fr = np.mean(fr[sample_mask,:], axis = (0,1))
    delay_fr = np.mean(fr[delay_mask,:], axis = (0,1))
    response_fr = np.mean(fr[response_mask,:], axis = (0,1))

    return sample_fr, delay_fr, response_fr

def get_mean_corr_and_trial_to_trial_variance(fr):
    '''
    Get the mean correlation and trial to trial variance for the firing rates.

    Parameters
    ----------
    fr : np.ndarray
        The firing rates [time,trial,neuron].

    Returns
    -------
    mean_corr : np.ndarray
        Mean correlation with the trial averaged firing rate. [neuron]
    trial_to_trial_var : np.ndarray
        Time averaged trial to trial variance. [neuron]
    '''
    trial_avg = fr.mean(axis = 1)
    mean_corr = np.zeros(fr.shape[-1])
    for i in range(fr.shape[-1]):
        mean_corr[i] = np.mean([np.corrcoef(trial_avg[:,i], fr[:,j,i])[0][1] for j in range(fr.shape[1])])
    
    trial_to_trial_var = np.mean(np.var(fr, axis = 1), axis = 0)
    return mean_corr, trial_to_trial_var


def calculate_selectivity(fr_R,fr_L, normalize = True):
    '''
    Returns the selectivity of each neuron.

    Parameters
    ----------
    fr_R : np.ndarray
        The firing rates for the right trials [trials,neurons].
    fr_L : np.ndarray
        The firing rates for the left trials [trials,neurons].
    normalize : bool, optional
        If True, normalizes the selectivity by the standard deviations,
        resulting in d'. Otherwise, returns the difference in means. 
        The default is True.

    Returns
    -------
    selectivity : np.ndarray
        The selectivity for each neuron.
    '''
    mean_R = fr_R.mean(axis = 0)
    mean_L = fr_L.mean(axis = 0)
    std_R = fr_R.std(axis = 0)
    std_L = fr_L.std(axis = 0)
    if normalize:
        selectivity = (mean_R - mean_L) / np.sqrt((std_R**2 + std_L**2) / 2)
    else:
        selectivity = mean_R - mean_L
    return selectivity

def calculate_auc(fr_R, fr_L, cv=5):
    '''
    Returns the AUC of each neuron.

    Parameters
    ----------
    fr_R : np.ndarray
        The firing rates for the right trials [trials,neurons].
    fr_L : np.ndarray
        The firing rates for the left trials [trials,neurons].
    cv : int, optional
        The number of folds for cross-validation. The default is 5.

    Returns
    -------
    auc : np.ndarray
        The AUC for each neuron.
    '''
    from sklearn.linear_model import LogisticRegression
    from sklearn.model_selection import StratifiedKFold, GridSearchCV
    from sklearn.metrics import roc_auc_score
    import numpy as np

    # Initialize AUC array
    auc = np.zeros(fr_R.shape[1])

    # Define parameter grid for logistic regression
    param_grid = {'C': [0.01, 0.1, 1, 10, 100]}

    for i in range(fr_R.shape[1]):
        # Prepare data for the i-th neuron
        y = np.concatenate([np.ones(fr_R.shape[0]), np.zeros(fr_L.shape[0])])
        X = np.concatenate([fr_R[:, i], fr_L[:, i]]).reshape(-1, 1)

        # Outer CV loop
        skf = StratifiedKFold(n_splits=cv)
        fold_aucs = []

        for train_index, test_index in skf.split(X, y):
            X_train, X_test = X[train_index], X[test_index]
            y_train, y_test = y[train_index], y[test_index]

            # Inner CV for hyperparameter tuning
            grid_search = GridSearchCV(
                LogisticRegression(solver='liblinear'),
                param_grid,
                cv=cv,
                scoring='roc_auc'
            )
            grid_search.fit(X_train, y_train)

            # Best logistic regression model
            best_model = grid_search.best_estimator_

            # Evaluate on the test set
            y_pred = best_model.predict_proba(X_test)[:, 1]
            fold_aucs.append(roc_auc_score(y_test, y_pred))

        # Average AUC across folds
        auc[i] = np.mean(fold_aucs)

    return auc
