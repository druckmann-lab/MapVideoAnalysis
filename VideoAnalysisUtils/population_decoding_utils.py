import pickle
import os 
import numpy as np
from sklearn.model_selection import StratifiedKFold, GridSearchCV
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import roc_auc_score
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA

def load_session(session_path, area = None):
    """
    Load session data from a specified path.
    Parameters
    ----------
    session_path : str
        Path to the session data directory.
    area : str, optional
        Specific area to filter session files by. If None, all files are loaded.
    Returns
    -------
    session_dict : dict
        Dictionary containing session data including ephys, CCF coordinates, labels, and trial information.
    """

    print('Loading session data from: ', session_path)
    session_files = [f for f in os.listdir(session_path) if f.endswith('.pickle')]
    if area is not None:
        session_files = [f for f in session_files if area in f]

    if len(session_files) == 0:
        print('No session files found.')
        return None

    fr_array = []
    ccf_coords = []
    ccf_labels = []
    is_alm = []

    for f in session_files:
        with open(session_path + '/' + f, 'rb') as handle:
            data = pickle.load(handle)
        if 'ALM' in f:
            is_alm.append(np.ones(data['fr'].shape[2]))
        else:
            is_alm.append(np.zeros(data['fr'].shape[2]))

        fr_array.append(data['fr'])
        ccf_coords.append(data['ccf_coordinate'])
        ccf_labels.append(np.array(data['ccf_label']))

    fr_array = np.concatenate(fr_array, axis=2)
    ccf_coords = np.concatenate(ccf_coords, axis=0)
    ccf_labels = np.concatenate(ccf_labels, axis=0)
    is_alm = np.concatenate(is_alm, axis=0)
    alm_inds = np.where(is_alm == 1)[0]

    session_dict = {
        'fr': fr_array,
        'ccf_coordinate': ccf_coords,
        'ccf_label': ccf_labels,
        'sess_name': data['sess_name'],
        'bin_centers': data['bin_centers'],
        'auto_learn_trials': data['auto_learn_trials'],
        'early_lick_trials': data['early_lick_trials'],
        'auto_water_trials': data['auto_water_trials'],
        'free_water_trials': data['free_water_trials'],
        'lick_directions': data['lick_directions'],
        'correctness': data['correctness'],
        'stimulation': data['stimulation'],
        'trial_type': data['trial_type'],
        'alm_inds': alm_inds,
    }
    return session_dict

def get_regular_trial_mask(ephys_data):
    '''
    Returns a mask for regular trials.
    
    No early lick, no auto water, no free water, 
    no no response trials, no stimulation.
    '''
    return (ephys_data['early_lick_trials'] == 0) \
         * (ephys_data['auto_water_trials'] == 0)  \
         * (ephys_data['free_water_trials'] == 0)  \
         * (ephys_data['correctness'] != -1) \
         * (ephys_data['stimulation'][:,0] == 0)

def get_ventral_medial_mask(ccf_coords):
    '''
    Returns mask for ventral-medial medulla.
    
    Applies global offset of (5700, 0, 5400) to ccf_coords.

    Filters for (ML) abs(coord[:,0]) <= 1200 and (DV) coord[:,1] >= 5200.
    '''
    global_offset_vec = np.array([5700, 0, 5400])
    coords = ccf_coords.copy() - global_offset_vec
    ventral_medial_mask = (coords[:,1] >= 5200) * (np.abs(coords[:,0]) <= 1200)
    return ventral_medial_mask

def nested_cross_validation(X, y, outer_k_folds=5, inner_k_folds = 10, npca = 16, C_range=[10**k for k in range(-3, 3)], use_scaler=False):
    """
    Perform nested cross-validation for logistic regression with PCA and scaling
    to decode binary labels from neural population activity.

    Parameters
    ----------
    X : np.ndarray
        Input data of shape (n_time, n_trials, n_features).
    y : np.ndarray
        Labels of shape (n_trials,).
    outer_k_folds : int, optional
        Number of outer cross-validation folds, by default 5.
    inner_k_folds : int, optional
        Number of inner cross-validation folds for hyperparameter tuning, by default 10.
    npca : int, optional
        Number of PCA components to keep, by default 16.
    C_range : list, optional
        Range of regularization parameters for logistic regression, by default [10**k for k in range(-3, 3)].
    use_scaler : bool, optional
        Whether to apply standard scaling to the data, by default False.

    Returns
    -------
    auc_scores : np.ndarray
        AUC scores for each time point and fold, shape (n_time, outer_k_folds).
    """
    n_time, n_trials, n_features = X.shape

    if n_features < 1:
        print('Zero neurons.')
        return None
    
    # Prepare cross-validation splits
    outer_cv = StratifiedKFold(n_splits=outer_k_folds, shuffle=True, random_state=42)
    
    auc_scores = np.zeros((n_time, outer_k_folds))

    for t in range(n_time):
        print(f"Processing time point {t+1}/{n_time}")
        
        X_t = X[t, :, :]
        
        for fold, (train_idx, test_idx) in enumerate(outer_cv.split(X_t,y)):
            X_train, X_test = X_t[train_idx], X_t[test_idx]
            y_train, y_test = y[train_idx], y[test_idx]

            if X_train.shape[1] > npca:
                pca = PCA(n_components=npca)
                X_train = pca.fit_transform(X_train)
                X_test = pca.transform(X_test) 

            if use_scaler:
                scaler = StandardScaler()
                X_train = scaler.fit_transform(X_train)
                X_test = scaler.transform(X_test)
            
            # Set up nested cross-validation for hyperparameter tuning
            grid = {'C': C_range}
            logistic = LogisticRegression(solver='liblinear')
            clf = GridSearchCV(logistic, grid, cv=inner_k_folds, scoring='roc_auc')
            clf.fit(X_train, y_train)
            
            # Evaluate on test set
            y_pred_proba = clf.predict_proba(X_test)[:, 1]
            auc = roc_auc_score(y_test, y_pred_proba)
            auc_scores[t, fold] = auc
            
    return auc_scores

        